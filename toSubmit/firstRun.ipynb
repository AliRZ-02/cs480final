{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class MixedDataset(Dataset):\n",
    "    def __init__(self, image_dir, bio_data, labels, ids, transform=None, train=True, train_stats = None):\n",
    "        self.image_dir = image_dir\n",
    "        self.bio_data = bio_data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.ids = ids\n",
    "        self.train = train\n",
    "        self.train_stats = train_stats\n",
    "\n",
    "        if train:\n",
    "            self.labels = torch.log10(self.labels)\n",
    "            self.mean = torch.mean(self.labels, dim=0)\n",
    "            self.std = torch.std(self.labels, dim=0)\n",
    "\n",
    "            mask = torch.abs(self.labels - self.mean) <= 3 * self.std\n",
    "            self.labels = self.labels[mask.all(dim=1)]\n",
    "            self.bio_data = self.bio_data[mask.all(dim=1)]\n",
    "            self.ids = self.ids[mask.all(dim=1)]\n",
    "\n",
    "            self.min_target = torch.min(self.labels, dim=0)[0]\n",
    "            self.max_target = torch.max(self.labels, dim=0)[0]\n",
    "            self.labels = (self.labels - self.min_target) / (self.max_target - self.min_target)\n",
    "\n",
    "            self.min_bio = torch.min(self.bio_data, dim=0)[0]\n",
    "            self.max_bio = torch.max(self.bio_data, dim=0)[0]\n",
    "            self.bio_data = (self.bio_data - self.min_bio) / (self.max_bio - self.min_bio)\n",
    "\n",
    "        else:\n",
    "            self.bio_data = (self.bio_data - self.train_stats[0]) / (self.train_stats[1] - self.train_stats[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.image_dir, f'{self.ids[idx].numpy()}.jpeg')).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n",
    "        \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32) if len(self.labels) != 0 else torch.tensor(0)\n",
    "        return image, bio_data, label\n",
    "\n",
    "class MixedDataModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MixedDataModel, self).__init__()\n",
    "\n",
    "        self.image_branch = models.resnet50(pretrained=True)\n",
    "        for param in self.image_branch.parameters():\n",
    "          param.requires_grad = False\n",
    "        \n",
    "        self.image_branch.fc.requires_grad = True\n",
    "\n",
    "        self.image_branch.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.image_branch.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "        )\n",
    "\n",
    "        self.bio_branch = nn.Sequential(\n",
    "            nn.Linear(163, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64)\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, bio_data):\n",
    "        image_out = self.image_branch(image)\n",
    "        bio_out = self.bio_branch(bio_data)\n",
    "        combined = torch.cat((image_out, bio_out), dim=1)\n",
    "        return self.regressor(combined)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation((0, 30)),\n",
    "    transforms.ColorJitter(contrast=(0.85, 1.15), saturation=(0.85, 1.15), brightness=(0.85, 1.15)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Lambda(lambda x: x.clamp(0, 1)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "csv_path = 'submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\train.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "ids = train_df.iloc[:, 0].to_numpy()\n",
    "features = train_df.iloc[:, 1:-6].to_numpy()\n",
    "labels = train_df.iloc[:, -6:].to_numpy()\n",
    "\n",
    "val_ids = val_df.iloc[:, 0].to_numpy()\n",
    "val_features = val_df.iloc[:, 1:-6].to_numpy()\n",
    "val_labels = val_df.iloc[:, -6:].to_numpy()\n",
    "\n",
    "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "ids_tensor = torch.tensor(ids, dtype=torch.int64)\n",
    "\n",
    "val_features_tensor = torch.tensor(val_features, dtype=torch.float32)\n",
    "val_labels_tensor = torch.tensor(val_labels, dtype=torch.float32)\n",
    "val_ids_tensor = torch.tensor(val_ids, dtype=torch.int64)\n",
    "\n",
    "mixed_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\train_images', features_tensor, labels_tensor, ids_tensor, transform=transform)\n",
    "train_loader = DataLoader(mixed_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\train_images', val_features_tensor, val_labels_tensor, val_ids_tensor, transform=test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = MixedDataModel()\n",
    "model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-3)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_19340\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n",
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_19340\\2161391897.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], dtype=torch.float32) if len(self.labels) != 0 else torch.tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 199 299 399 499 599 699 799 899  \n",
      "2.09178637686046 Epoch [1/50], Loss: 0.0397\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "1.1248792465399151 Epoch [2/50], Loss: 0.0295\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.44005913567929134 Epoch [3/50], Loss: 0.0277\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.31140336466704305 Epoch [4/50], Loss: 0.0270\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.20208164554858496 Epoch [5/50], Loss: 0.0266\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.13836954712023136 Epoch [6/50], Loss: 0.0262\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.2417149781456843 Epoch [7/50], Loss: 0.0259\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.12266816654306674 Epoch [8/50], Loss: 0.0257\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.06501983036758446 Epoch [9/50], Loss: 0.0255\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.05670361201229848 Epoch [10/50], Loss: 0.0253\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0343174802192189 Epoch [11/50], Loss: 0.0252\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03851066565193869 Epoch [12/50], Loss: 0.0251\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03273337990467848 Epoch [13/50], Loss: 0.0251\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030645273429782766 Epoch [14/50], Loss: 0.0250\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030117526099930406 Epoch [15/50], Loss: 0.0248\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03470615970973785 Epoch [16/50], Loss: 0.0248\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030727727172768067 Epoch [17/50], Loss: 0.0246\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030346977498065603 Epoch [18/50], Loss: 0.0246\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.02972250644434319 Epoch [19/50], Loss: 0.0246\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03051098177458352 Epoch [20/50], Loss: 0.0244\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03145927366487652 Epoch [21/50], Loss: 0.0245\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03035250781217085 Epoch [22/50], Loss: 0.0244\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03279832825969588 Epoch [23/50], Loss: 0.0243\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03731504867705498 Epoch [24/50], Loss: 0.0242\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.031868534185263794 Epoch [25/50], Loss: 0.0243\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03304452371787325 Epoch [26/50], Loss: 0.0242\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03878775698242159 Epoch [27/50], Loss: 0.0242\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.035021421081020764 Epoch [28/50], Loss: 0.0241\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.039755768651663054 Epoch [29/50], Loss: 0.0241\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.04429276994908387 Epoch [30/50], Loss: 0.0240\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.041316183578026924 Epoch [31/50], Loss: 0.0240\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0323335791180129 Epoch [32/50], Loss: 0.0240\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0348975490099988 Epoch [33/50], Loss: 0.0239\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.06694532814718451 Epoch [34/50], Loss: 0.0240\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.044585867426716365 Epoch [35/50], Loss: 0.0238\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03582209554549895 Epoch [36/50], Loss: 0.0238\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03730037217952221 Epoch [37/50], Loss: 0.0238\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03765252611867571 Epoch [38/50], Loss: 0.0239\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.033710700373055964 Epoch [39/50], Loss: 0.0237\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030669559630365505 Epoch [40/50], Loss: 0.0237\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.04352008064959937 Epoch [41/50], Loss: 0.0237\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03689632854360318 Epoch [42/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03259541356732488 Epoch [43/50], Loss: 0.0237\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03136758426362686 Epoch [44/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03996363925457242 Epoch [45/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03477546395470015 Epoch [46/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037151181436924315 Epoch [47/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03736492140060253 Epoch [48/50], Loss: 0.0235\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03506520389756452 Epoch [49/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.032585706795577096 Epoch [50/50], Loss: 0.0235\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if (i % 100 == 99):\n",
    "          print(i, end = ' ')\n",
    "        images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    print(' ')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        print(val_loss / len(val_loader), end = ' ')\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./models/modelV5_epoch_{epoch}.pth')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'overfitV7.json', 'w') as f:\n",
    "    json.dump({\n",
    "        \"train\": train_losses,\n",
    "        \"val\": val_losses\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixedDataModel(\n",
       "  (image_branch): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bio_branch): Sequential(\n",
       "    (0): Linear(in_features=163, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MixedDataModel()\n",
    "model.load_state_dict(torch.load('./models/modelV5_epoch_49.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_19340\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "test_csv_path = 'submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test.csv'\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "test_ids = test_df.iloc[:, 0]\n",
    "test_features = test_df.iloc[:, 1:].to_numpy()\n",
    "\n",
    "test_features_tensor = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_ids_tensor = torch.tensor(test_ids.to_numpy(), dtype=torch.int64)\n",
    "\n",
    "test_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test_images', test_features_tensor, [], test_ids_tensor, transform=test_transform, train=False, train_stats=(mixed_dataset.min_bio, mixed_dataset.max_bio, mixed_dataset.min_target, mixed_dataset.max_target))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "torch.cuda.empty_cache()\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    inputs, images, labels = data[0].to(device), data[1].to(device), None\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs, images)\n",
    "    outputs = (outputs * (mixed_dataset.max_target.to(device) - mixed_dataset.min_target.to(device))) + mixed_dataset.min_target.to(device)\n",
    "    outputs = torch.pow(10, outputs)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    preds.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "res = pd.DataFrame(np.concatenate(preds), columns = [\"X4\", \"X11\", \"X18\", \"X26\", \"X50\", \"X3112\"])\n",
    "res = pd.concat([test_ids, res], axis=1)\n",
    "res.to_csv('./19Attempt.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
