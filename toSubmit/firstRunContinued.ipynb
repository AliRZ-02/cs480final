{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# gpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's define the dataset class to take in images and vectors, and the NN itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class MixedDataset(Dataset):\n",
    "    def __init__(self, image_dir, bio_data, labels, ids, transform=None, train=True, train_stats = None):\n",
    "        self.image_dir = image_dir\n",
    "        self.bio_data = bio_data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.ids = ids\n",
    "        self.train = train\n",
    "        self.train_stats = train_stats\n",
    "\n",
    "        if train:\n",
    "            self.labels = torch.log10(self.labels)\n",
    "            self.mean = torch.mean(self.labels, dim=0)\n",
    "            self.std = torch.std(self.labels, dim=0)\n",
    "\n",
    "            mask = torch.abs(self.labels - self.mean) <= 3 * self.std\n",
    "            self.labels = self.labels[mask.all(dim=1)]\n",
    "            self.bio_data = self.bio_data[mask.all(dim=1)]\n",
    "            self.ids = self.ids[mask.all(dim=1)]\n",
    "\n",
    "            self.min_target = torch.min(self.labels, dim=0)[0]\n",
    "            self.max_target = torch.max(self.labels, dim=0)[0]\n",
    "            self.labels = (self.labels - self.min_target) / (self.max_target - self.min_target)\n",
    "\n",
    "            self.min_bio = torch.min(self.bio_data, dim=0)[0]\n",
    "            self.max_bio = torch.max(self.bio_data, dim=0)[0]\n",
    "            self.bio_data = (self.bio_data - self.min_bio) / (self.max_bio - self.min_bio)\n",
    "\n",
    "        else:\n",
    "            self.bio_data = (self.bio_data - self.train_stats[0]) / (self.train_stats[1] - self.train_stats[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(os.path.join(self.image_dir, f'{self.ids[idx].numpy()}.jpeg')).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n",
    "\n",
    "        # we don't have labels for the test set\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32) if len(self.labels) != 0 else torch.tensor(0)\n",
    "        return image, bio_data, label\n",
    "\n",
    "class MixedDataModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MixedDataModel, self).__init__()\n",
    "\n",
    "        self.image_branch = models.resnet50(pretrained=True)\n",
    "        for param in self.image_branch.parameters():\n",
    "          param.requires_grad = False\n",
    "        \n",
    "        self.image_branch.fc.requires_grad = True\n",
    "\n",
    "        # this is the layer that comes off right from the resnet model\n",
    "        self.image_branch.fc = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.image_branch.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "        )\n",
    "\n",
    "        # this is the numerical input layers\n",
    "        self.bio_branch = nn.Sequential(\n",
    "            nn.Linear(163, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64)\n",
    "        )\n",
    "\n",
    "        # this is the concatenation + regression layer\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 6)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, bio_data):\n",
    "        image_out = self.image_branch(image)\n",
    "        bio_out = self.bio_branch(bio_data)\n",
    "        combined = torch.cat((image_out, bio_out), dim=1)\n",
    "        return self.regressor(combined)\n",
    "\n",
    "# random transofrmations/augmentations to build robustness\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation((0, 30)),\n",
    "    transforms.ColorJitter(contrast=(0.85, 1.15), saturation=(0.85, 1.15), brightness=(0.85, 1.15)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Lambda(lambda x: x.clamp(0, 1)),\n",
    "])\n",
    "\n",
    "# just normalize for testing and validation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's instantiate our model, the loss function and the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "csv_path = 'submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\train.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "ids = train_df.iloc[:, 0].to_numpy()\n",
    "features = train_df.iloc[:, 1:-6].to_numpy()\n",
    "labels = train_df.iloc[:, -6:].to_numpy()\n",
    "\n",
    "val_ids = val_df.iloc[:, 0].to_numpy()\n",
    "val_features = val_df.iloc[:, 1:-6].to_numpy()\n",
    "val_labels = val_df.iloc[:, -6:].to_numpy()\n",
    "\n",
    "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(labels, dtype=torch.float32)\n",
    "ids_tensor = torch.tensor(ids, dtype=torch.int64)\n",
    "\n",
    "val_features_tensor = torch.tensor(val_features, dtype=torch.float32)\n",
    "val_labels_tensor = torch.tensor(val_labels, dtype=torch.float32)\n",
    "val_ids_tensor = torch.tensor(val_ids, dtype=torch.int64)\n",
    "\n",
    "mixed_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\train_images', features_tensor, labels_tensor, ids_tensor, transform=transform)\n",
    "train_loader = DataLoader(mixed_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\train_images', val_features_tensor, val_labels_tensor, val_ids_tensor, transform=test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = MixedDataModel()\n",
    "model.to(device)\n",
    "\n",
    "# define MSE loss and adamw optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-3)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's train for 50 epochs with the current lr of 0.0001 and decay rate of 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_19340\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n",
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_19340\\2161391897.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], dtype=torch.float32) if len(self.labels) != 0 else torch.tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 199 299 399 499 599 699 799 899  \n",
      "2.09178637686046 Epoch [1/50], Loss: 0.0397\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "1.1248792465399151 Epoch [2/50], Loss: 0.0295\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.44005913567929134 Epoch [3/50], Loss: 0.0277\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.31140336466704305 Epoch [4/50], Loss: 0.0270\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.20208164554858496 Epoch [5/50], Loss: 0.0266\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.13836954712023136 Epoch [6/50], Loss: 0.0262\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.2417149781456843 Epoch [7/50], Loss: 0.0259\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.12266816654306674 Epoch [8/50], Loss: 0.0257\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.06501983036758446 Epoch [9/50], Loss: 0.0255\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.05670361201229848 Epoch [10/50], Loss: 0.0253\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0343174802192189 Epoch [11/50], Loss: 0.0252\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03851066565193869 Epoch [12/50], Loss: 0.0251\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03273337990467848 Epoch [13/50], Loss: 0.0251\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030645273429782766 Epoch [14/50], Loss: 0.0250\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030117526099930406 Epoch [15/50], Loss: 0.0248\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03470615970973785 Epoch [16/50], Loss: 0.0248\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030727727172768067 Epoch [17/50], Loss: 0.0246\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030346977498065603 Epoch [18/50], Loss: 0.0246\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.02972250644434319 Epoch [19/50], Loss: 0.0246\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03051098177458352 Epoch [20/50], Loss: 0.0244\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03145927366487652 Epoch [21/50], Loss: 0.0245\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03035250781217085 Epoch [22/50], Loss: 0.0244\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03279832825969588 Epoch [23/50], Loss: 0.0243\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03731504867705498 Epoch [24/50], Loss: 0.0242\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.031868534185263794 Epoch [25/50], Loss: 0.0243\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03304452371787325 Epoch [26/50], Loss: 0.0242\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03878775698242159 Epoch [27/50], Loss: 0.0242\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.035021421081020764 Epoch [28/50], Loss: 0.0241\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.039755768651663054 Epoch [29/50], Loss: 0.0241\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.04429276994908387 Epoch [30/50], Loss: 0.0240\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.041316183578026924 Epoch [31/50], Loss: 0.0240\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0323335791180129 Epoch [32/50], Loss: 0.0240\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0348975490099988 Epoch [33/50], Loss: 0.0239\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.06694532814718451 Epoch [34/50], Loss: 0.0240\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.044585867426716365 Epoch [35/50], Loss: 0.0238\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03582209554549895 Epoch [36/50], Loss: 0.0238\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03730037217952221 Epoch [37/50], Loss: 0.0238\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03765252611867571 Epoch [38/50], Loss: 0.0239\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.033710700373055964 Epoch [39/50], Loss: 0.0237\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030669559630365505 Epoch [40/50], Loss: 0.0237\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.04352008064959937 Epoch [41/50], Loss: 0.0237\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03689632854360318 Epoch [42/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03259541356732488 Epoch [43/50], Loss: 0.0237\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03136758426362686 Epoch [44/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03996363925457242 Epoch [45/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03477546395470015 Epoch [46/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037151181436924315 Epoch [47/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03736492140060253 Epoch [48/50], Loss: 0.0235\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03506520389756452 Epoch [49/50], Loss: 0.0236\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.032585706795577096 Epoch [50/50], Loss: 0.0235\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if (i % 100 == 99):\n",
    "          print(i, end = ' ')\n",
    "        images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    print(' ')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        print(val_loss / len(val_loader), end = ' ')\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./models/modelV5_epoch_{epoch}.pth')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's save the losses and reload the last model saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'overfitV7.json', 'w') as f:\n",
    "    json.dump({\n",
    "        \"train\": train_losses,\n",
    "        \"val\": val_losses\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixedDataModel(\n",
       "  (image_branch): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bio_branch): Sequential(\n",
       "    (0): Linear(in_features=163, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MixedDataModel()\n",
    "model.load_state_dict(torch.load('./models/modelV5_epoch_49.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create the test outputs to submit on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_19340\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "test_csv_path = 'submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test.csv'\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "test_ids = test_df.iloc[:, 0]\n",
    "test_features = test_df.iloc[:, 1:].to_numpy()\n",
    "\n",
    "test_features_tensor = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_ids_tensor = torch.tensor(test_ids.to_numpy(), dtype=torch.int64)\n",
    "\n",
    "test_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test_images', test_features_tensor, [], test_ids_tensor, transform=test_transform, train=False, train_stats=(mixed_dataset.min_bio, mixed_dataset.max_bio, mixed_dataset.min_target, mixed_dataset.max_target))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "torch.cuda.empty_cache()\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    inputs, images, labels = data[0].to(device), data[1].to(device), None\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs, images)\n",
    "\n",
    "    # this is to unnormalize\n",
    "    outputs = (outputs * (mixed_dataset.max_target.to(device) - mixed_dataset.min_target.to(device))) + mixed_dataset.min_target.to(device)\n",
    "    outputs = torch.pow(10, outputs)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    preds.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "res = pd.DataFrame(np.concatenate(preds), columns = [\"X4\", \"X11\", \"X18\", \"X26\", \"X50\", \"X3112\"])\n",
    "res = pd.concat([test_ids, res], axis=1)\n",
    "res.to_csv('./19Attempt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce Training Rate & Try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n",
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], dtype=torch.float32) if len(self.labels) != 0 else torch.tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03222226300974365 Epoch [51/50], Loss: 0.0234\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03179707584020339 Epoch [52/50], Loss: 0.0234\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03360502202410688 Epoch [53/50], Loss: 0.0234\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03312361481701314 Epoch [54/50], Loss: 0.0234\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03590898579250463 Epoch [55/50], Loss: 0.0234\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03431298272299622 Epoch [56/50], Loss: 0.0234\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.035321263264608285 Epoch [57/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03485799571763166 Epoch [58/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03397218679428583 Epoch [59/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.033260680780357675 Epoch [60/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03314719291833731 Epoch [61/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.032283000557528814 Epoch [62/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03470137228186314 Epoch [63/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03451848819640725 Epoch [64/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03331940212411436 Epoch [65/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.035395489900037345 Epoch [66/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.036502874641102336 Epoch [67/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.033219779634222325 Epoch [68/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.036295624857067096 Epoch [69/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03525457237866002 Epoch [70/50], Loss: 0.0233\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.035180661246663164 Epoch [71/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.033468892526349076 Epoch [72/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03394618185485906 Epoch [73/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.034022919162504585 Epoch [74/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03593073496481909 Epoch [75/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03512990444536634 Epoch [76/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03530676851448743 Epoch [77/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03666774139773508 Epoch [78/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.032948863817009365 Epoch [79/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03457269150205711 Epoch [80/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03291084072910822 Epoch [81/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03276852507762581 Epoch [82/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03374014124425075 Epoch [83/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03532615662948323 Epoch [84/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.034069661028411705 Epoch [85/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03301963247057156 Epoch [86/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03283035877322861 Epoch [87/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03727162094703811 Epoch [88/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03647432449134255 Epoch [89/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.04023405812258421 Epoch [90/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03512764486827349 Epoch [91/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.04189971786158288 Epoch [92/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.038010462281494004 Epoch [93/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03658105803253921 Epoch [94/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03562479082736288 Epoch [95/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0361273786513067 Epoch [96/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03941004138877276 Epoch [97/50], Loss: 0.0232\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.034134409062353224 Epoch [98/50], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037417012308290615 Epoch [99/50], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037914033617205946 Epoch [100/50], Loss: 0.0230\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00001, weight_decay=1e-2)\n",
    "\n",
    "num_epochs = 50\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(50, 50+num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if (i % 100 == 99):\n",
    "          print(i, end = ' ')\n",
    "        images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    print(' ')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        print(val_loss / len(val_loader), end = ' ')\n",
    "    \n",
    "    if (epoch % 5 ==4):\n",
    "        torch.save(model.state_dict(), f'./models/modelV5_epoch_{epoch}.pth')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MixedDataModel(\n",
       "  (image_branch): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bio_branch): Sequential(\n",
       "    (0): Linear(in_features=163, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MixedDataModel()\n",
    "model.load_state_dict(torch.load('./models/modelV5_epoch_99.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "test_csv_path = 'submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test.csv'\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "test_ids = test_df.iloc[:, 0]\n",
    "test_features = test_df.iloc[:, 1:].to_numpy()\n",
    "\n",
    "test_features_tensor = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_ids_tensor = torch.tensor(test_ids.to_numpy(), dtype=torch.int64)\n",
    "\n",
    "test_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test_images', test_features_tensor, [], test_ids_tensor, transform=test_transform, train=False, train_stats=(mixed_dataset.min_bio, mixed_dataset.max_bio, mixed_dataset.min_target, mixed_dataset.max_target))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "torch.cuda.empty_cache()\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    inputs, images, labels = data[0].to(device), data[1].to(device), None\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs, images)\n",
    "    outputs = (outputs * (mixed_dataset.max_target.to(device) - mixed_dataset.min_target.to(device))) + mixed_dataset.min_target.to(device)\n",
    "    outputs = torch.pow(10, outputs)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    preds.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "res = pd.DataFrame(np.concatenate(preds), columns = [\"X4\", \"X11\", \"X18\", \"X26\", \"X50\", \"X3112\"])\n",
    "res = pd.concat([test_ids, res], axis=1)\n",
    "res.to_csv('./21Attempt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'overfitV9.json', 'w') as f:\n",
    "    json.dump({\n",
    "        \"train\": train_losses,\n",
    "        \"val\": val_losses\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to train on larger training rate to get out of plateaued loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n",
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], dtype=torch.float32) if len(self.labels) != 0 else torch.tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 199 299 399 499 599 699 799 899  \n",
      "0.030247019852703883 Epoch [101/5], Loss: 0.0258\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03412025857731881 Epoch [102/5], Loss: 0.0255\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03537846462959461 Epoch [103/5], Loss: 0.0253\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03397051571502618 Epoch [104/5], Loss: 0.0252\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.06405298420895449 Epoch [105/5], Loss: 0.0251\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "\n",
    "num_epochs = 5\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(100, 100+num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if (i % 100 == 99):\n",
    "          print(i, end = ' ')\n",
    "        images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    print(' ')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        print(val_loss / len(val_loader), end = ' ')\n",
    "    \n",
    "    if (epoch % 5 ==4):\n",
    "        torch.save(model.state_dict(), f'./models/modelV5_epoch_{epoch}.pth')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "didn't work, let's revert and keep training for 60 more epochs and with a smaller learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MixedDataModel(\n",
       "  (image_branch): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bio_branch): Sequential(\n",
       "    (0): Linear(in_features=163, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MixedDataModel()\n",
    "model.load_state_dict(torch.load('./models/modelV5_epoch_99.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n",
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], dtype=torch.float32) if len(self.labels) != 0 else torch.tensor(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0372272002612531 Epoch [101/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03606941060800301 Epoch [102/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.036822258649386375 Epoch [103/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03775363416233767 Epoch [104/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03617276506204354 Epoch [105/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03851354372525505 Epoch [106/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0378332122828555 Epoch [107/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03804623510552804 Epoch [108/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0383590253801481 Epoch [109/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.038160578268561285 Epoch [110/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03879603876276055 Epoch [111/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03874219257972742 Epoch [112/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03970272690510219 Epoch [113/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03863503602955506 Epoch [114/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03693809884370339 Epoch [115/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03785189821833541 Epoch [116/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03606318266919026 Epoch [117/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037327740039782 Epoch [118/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03657690909981486 Epoch [119/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03991090090047975 Epoch [120/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.038628603765356394 Epoch [121/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037713406094715664 Epoch [122/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03683623118016884 Epoch [123/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03742729027864904 Epoch [124/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03840191997889324 Epoch [125/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03758105769120006 Epoch [126/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03703220601868533 Epoch [127/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03780698517586297 Epoch [128/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03924556933192589 Epoch [129/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0362179863534355 Epoch [130/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0363222626735445 Epoch [131/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037562117772365386 Epoch [132/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0378853453526854 Epoch [133/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.041121640306735326 Epoch [134/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03999697052032841 Epoch [135/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037550013670735516 Epoch [136/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03988313524859396 Epoch [137/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037447813227169426 Epoch [138/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03881608678201432 Epoch [139/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03676535800732823 Epoch [140/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.0375836350491293 Epoch [141/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.04045425827505617 Epoch [142/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03828677998833087 Epoch [143/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03785998264124036 Epoch [144/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03670649669370671 Epoch [145/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037769477739025226 Epoch [146/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037854581015554035 Epoch [147/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037811432569193455 Epoch [148/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03774849468698868 Epoch [149/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.038726487359114985 Epoch [150/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03919047283136893 Epoch [151/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03800128855052506 Epoch [152/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03806034231234176 Epoch [153/60], Loss: 0.0229\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03555563230233395 Epoch [154/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037096685266144847 Epoch [155/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.039157013729335326 Epoch [156/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.03600347698157133 Epoch [157/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.039519919587774316 Epoch [158/60], Loss: 0.0231\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037499029702141216 Epoch [159/60], Loss: 0.0230\n",
      "99 199 299 399 499 599 699 799 899  \n",
      "0.037016787283454346 Epoch [160/60], Loss: 0.0230\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.000001, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 60\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(100, 100+num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if (i % 100 == 99):\n",
    "          print(i, end = ' ')\n",
    "        images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    print(' ')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            images, inputs, labels = data[0].to(device), data[1].to(device), data[2].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "        \n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        print(val_loss / len(val_loader), end = ' ')\n",
    "    \n",
    "    if (epoch % 5 ==4):\n",
    "        torch.save(model.state_dict(), f'./models/modelV5_epoch_{epoch}.pth')\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MixedDataModel(\n",
       "  (image_branch): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Dropout(p=0.2, inplace=False)\n",
       "      (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (4): ReLU()\n",
       "      (5): Dropout(p=0.2, inplace=False)\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): ReLU()\n",
       "      (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (bio_branch): Sequential(\n",
       "    (0): Linear(in_features=163, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MixedDataModel()\n",
    "model.load_state_dict(torch.load('./models/modelV5_epoch_104.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "test_csv_path = 'submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test.csv'\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "test_ids = test_df.iloc[:, 0]\n",
    "test_features = test_df.iloc[:, 1:].to_numpy()\n",
    "\n",
    "test_features_tensor = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_ids_tensor = torch.tensor(test_ids.to_numpy(), dtype=torch.int64)\n",
    "\n",
    "test_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test_images', test_features_tensor, [], test_ids_tensor, transform=test_transform, train=False, train_stats=(mixed_dataset.min_bio, mixed_dataset.max_bio, mixed_dataset.min_target, mixed_dataset.max_target))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "torch.cuda.empty_cache()\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    inputs, images, labels = data[0].to(device), data[1].to(device), None\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs, images)\n",
    "    outputs = (outputs * (mixed_dataset.max_target.to(device) - mixed_dataset.min_target.to(device))) + mixed_dataset.min_target.to(device)\n",
    "    outputs = torch.pow(10, outputs)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    preds.append(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "res = pd.DataFrame(np.concatenate(preds), columns = [\"X4\", \"X11\", \"X18\", \"X26\", \"X50\", \"X3112\"])\n",
    "res = pd.concat([test_ids, res], axis=1)\n",
    "res.to_csv('./24Attempt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f'overfitV10.json', 'w') as f:\n",
    "    json.dump({\n",
    "        \"train\": train_losses,\n",
    "        \"val\": val_losses\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's look at some statistics for our data for the paper and run our best algorithm several times to get the average r-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0294e+01, 8.3925e+03, 2.4490e+03, 1.6958e+02, 1.8245e+03, 6.3641e+01,\n",
      "        1.6400e+02, 1.9100e+02, 1.7800e+02, 1.8500e+02, 1.7000e+02, 1.8900e+02,\n",
      "        7.9500e+02, 5.8500e+02, 6.2200e+02, 6.2500e+02, 6.1700e+02, 5.8400e+02,\n",
      "        4.4900e+02, 5.1600e+02, 4.6200e+02, 4.5900e+02, 4.4800e+02, 4.7800e+02,\n",
      "        6.0100e+02, 7.0800e+02, 6.4200e+02, 6.9500e+02, 6.0400e+02, 7.0300e+02,\n",
      "        2.4650e+03, 1.4180e+03, 2.3230e+03, 2.1580e+03, 2.3200e+03, 1.5210e+03,\n",
      "        1.0150e+03, 9.9000e+02, 9.3000e+02, 8.1200e+02, 9.9100e+02, 9.2000e+02,\n",
      "        1.7300e+02, 9.1000e+01, 9.5000e+01, 9.1000e+01, 9.2000e+01, 9.1000e+01,\n",
      "        9.5000e+01, 9.6300e+02, 9.6000e+02, 9.6900e+02, 9.6100e+02, 9.6200e+02,\n",
      "        9.5400e+02, 7.7500e+02, 7.0800e+02, 7.4000e+02, 7.1900e+02, 7.7700e+02,\n",
      "        7.1200e+02, 3.7980e+03, 4.2500e+03, 3.2980e+03, 4.0110e+03, 3.4600e+03,\n",
      "        4.2650e+03, 1.3283e+04, 1.2900e+04, 1.2127e+04, 1.2981e+04, 7.2850e+03,\n",
      "        7.9990e+03, 7.8210e+03, 7.2770e+03, 7.7920e+03, 6.2880e+03, 1.1216e+04,\n",
      "        1.1021e+04, 9.8900e+03, 1.0818e+04, 6.3320e+03, 1.3804e+04, 1.3246e+04,\n",
      "        1.2009e+04, 1.3456e+04, 7.3990e+03, 1.2522e+04, 1.1889e+04, 1.1591e+04,\n",
      "        1.2271e+04, 6.5190e+03, 1.1236e+04, 1.0705e+04, 1.0527e+04, 1.1078e+04,\n",
      "        6.3490e+03, 1.0001e+04, 9.4090e+03, 9.7080e+03, 1.0016e+04, 6.3120e+03,\n",
      "        8.7990e+03, 7.9400e+03, 8.6180e+03, 8.7980e+03, 6.2940e+03, 8.6140e+03,\n",
      "        8.0590e+03, 8.1140e+03, 8.5270e+03, 6.2270e+03, 1.0173e+04, 9.4810e+03,\n",
      "        9.3330e+03, 1.0052e+04, 6.2820e+03, 9.5860e+03, 8.9880e+03, 9.1010e+03,\n",
      "        9.4820e+03, 6.2740e+03, 8.4020e+03, 7.4860e+03, 8.1730e+03, 8.4540e+03,\n",
      "        6.3010e+03, 7.2435e-01, 7.3685e-01, 7.6345e-01, 7.7730e-01, 7.6730e-01,\n",
      "        7.7738e-01, 7.8162e-01, 7.9140e-01, 7.8527e-01, 8.0048e-01, 9.2829e-01,\n",
      "        9.6517e-01, 1.8512e+00, 1.8289e+00, 1.8283e+00, 1.8500e+00, 1.8099e+00,\n",
      "        1.8169e+00, 1.8370e+00, 1.8592e+00, 1.8641e+00, 1.8355e+00, 1.8612e+00,\n",
      "        1.8689e+00, 7.7262e-01, 7.7835e-01, 7.7384e-01, 7.9107e-01, 7.9523e-01,\n",
      "        8.1492e-01, 8.3968e-01, 8.3923e-01, 8.3662e-01, 8.1379e-01, 8.0083e-01,\n",
      "        7.6459e-01])\n",
      "tensor([-1.3731e+01,  0.0000e+00,  0.0000e+00,  0.0000e+00,  9.8771e+00,\n",
      "         7.6600e+00,  2.9000e+01,  4.7000e+01,  4.3000e+01,  4.7000e+01,\n",
      "         4.1000e+01,  4.6000e+01,  5.1000e+01,  2.2000e+01,  2.5000e+01,\n",
      "         2.3000e+01,  2.6000e+01,  2.2000e+01,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.7000e+01,\n",
      "         2.1000e+01,  1.0000e+01,  1.8000e+01,  1.6000e+01,  2.4000e+01,\n",
      "         2.3000e+01,  3.0000e+00,  1.5000e+01,  5.0000e+00,  2.2000e+01,\n",
      "         5.0000e+00,  5.1000e+01,  6.0000e+00,  4.4000e+01,  3.7000e+01,\n",
      "         4.8000e+01,  2.6000e+01,  6.0000e+00,  4.0000e+01,  4.4000e+01,\n",
      "         4.1000e+01,  4.3000e+01,  4.0000e+01,  4.4000e+01,  1.7000e+01,\n",
      "         1.2000e+01,  1.7000e+01,  1.5000e+01,  1.8000e+01,  1.3000e+01,\n",
      "         2.0000e+01,  1.9000e+01,  1.8000e+01,  1.9000e+01,  1.9000e+01,\n",
      "         1.8000e+01,  1.9000e+01,  5.0000e+00,  1.5000e+01,  7.0000e+00,\n",
      "         1.2000e+01,  4.0000e+00,  6.7000e+01,  8.5000e+01,  1.0000e+00,\n",
      "         9.8000e+01,  4.5000e+01,  9.4000e+01,  2.3300e+02,  4.0000e+00,\n",
      "         1.5800e+02,  3.6100e+02,  1.0700e+02,  2.8400e+02,  8.0000e+00,\n",
      "         1.5400e+02,  3.1000e+02,  8.0000e+00,  1.6000e+01,  2.0000e+00,\n",
      "         1.0000e+00,  1.9000e+01,  8.1000e+01,  3.2200e+02,  8.0000e+00,\n",
      "         1.4900e+02,  3.8400e+02,  7.9000e+01,  3.4600e+02, -3.2000e+01,\n",
      "         1.3300e+02,  3.5100e+02,  8.7000e+01,  2.9000e+02, -1.3000e+01,\n",
      "         1.0600e+02,  3.5100e+02,  1.0200e+02,  3.3400e+02,  4.4000e+01,\n",
      "         1.2900e+02,  2.9900e+02,  1.0100e+02,  3.5100e+02,  4.0000e+01,\n",
      "         1.5600e+02,  2.2600e+02,  9.2000e+01,  3.5200e+02, -7.0000e+00,\n",
      "         1.7900e+02,  3.6300e+02,  1.0200e+02,  2.5500e+02,  4.3000e+01,\n",
      "         1.5900e+02,  3.3700e+02,  7.6000e+01,  2.3200e+02,  1.6000e+01,\n",
      "         9.8000e+01,  3.5900e+02,  4.9674e-03,  5.5498e-03,  4.2844e-03,\n",
      "         4.8784e-03,  6.9056e-04,  1.8062e-03,  1.0294e-03,  1.7561e-03,\n",
      "         3.1050e-03,  5.9259e-03,  4.9721e-03,  5.3929e-03,  1.3386e-01,\n",
      "         1.1199e-01,  1.3317e-01,  1.3043e-01,  1.2087e-01,  1.2196e-01,\n",
      "         1.3342e-01,  1.3646e-01,  1.2794e-01,  1.2544e-01,  1.2985e-01,\n",
      "         1.3247e-01,  1.3437e-02,  8.9905e-03,  1.1598e-02,  8.4217e-03,\n",
      "         9.0682e-03,  5.6153e-03,  5.6085e-03,  8.6413e-03,  7.3198e-03,\n",
      "         7.6393e-03,  1.0804e-02,  1.0485e-02])\n",
      "tensor([5.8249e-02, 1.9990e-02, 9.5009e-05, 7.9744e-03, 1.6727e-02, 2.4323e-03])\n",
      "tensor([0.0115, 2.1706, 4.2945, 3.5418, 1.1790, 5.6011])\n",
      "tensor([0.1384, 2.2305, 4.2948, 3.5655, 1.2292, 5.6084])\n",
      "tensor([-0.1623,  2.1267,  4.2944,  3.5390,  1.1337,  5.5994])\n",
      "24121830\n",
      "31656\n",
      "43363\n"
     ]
    }
   ],
   "source": [
    "print(mixed_dataset.max_bio)\n",
    "print(mixed_dataset.min_bio)\n",
    "print(mixed_dataset.std)\n",
    "print(mixed_dataset.mean)\n",
    "print(mixed_dataset.max_target)\n",
    "print(mixed_dataset.min_target)\n",
    "print(sum([param.numel() for param in model.parameters()]))\n",
    "print(len(mixed_dataset))\n",
    "print(len(df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Alirz\\Documents\\2024 - UW\\S2024\\CS480\\Final\\project\\project\\venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\2161391897.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  bio_data = torch.tensor(self.bio_data[idx], dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "model = MixedDataModel()\n",
    "model.load_state_dict(torch.load('./models/modelV5_epoch_99.pth'))\n",
    "model.to(device)\n",
    "\n",
    "preds = []\n",
    "test_csv_path = 'submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test.csv'\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "test_ids = test_df.iloc[:, 0]\n",
    "test_features = test_df.iloc[:, 1:].to_numpy()\n",
    "\n",
    "test_features_tensor = torch.tensor(test_features, dtype=torch.float32)\n",
    "test_ids_tensor = torch.tensor(test_ids.to_numpy(), dtype=torch.int64)\n",
    "\n",
    "test_dataset = MixedDataset('submit\\\\data\\\\cs-480-2024-spring\\\\data\\\\test_images', test_features_tensor, [], test_ids_tensor, transform=test_transform, train=False, train_stats=(mixed_dataset.min_bio, mixed_dataset.max_bio, mixed_dataset.min_target, mixed_dataset.max_target))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "torch.cuda.empty_cache()\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    inputs, images, labels = data[0].to(device), data[1].to(device), None\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs, images)\n",
    "    outputs = (outputs * (mixed_dataset.max_target.to(device) - mixed_dataset.min_target.to(device))) + mixed_dataset.min_target.to(device)\n",
    "    outputs = torch.pow(10, outputs)\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    preds.append(outputs)\n",
    "\n",
    "res = pd.DataFrame(np.concatenate(preds), columns = [\"X4\", \"X11\", \"X18\", \"X26\", \"X50\", \"X3112\"])\n",
    "res = pd.concat([test_ids, res], axis=1)\n",
    "res.to_csv('./BestAttempt_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's plot the traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alirz\\AppData\\Local\\Temp\\ipykernel_15076\\1972149549.py:9: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(['X4', 'X11', 'X18', 'X26', 'X50', 'X3112'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "box_data = []\n",
    "for index in range(6):\n",
    "    box_data.append(mixed_dataset.labels[:, index].numpy())\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "ax.set_xticklabels(['X4', 'X11', 'X18', 'X26', 'X50', 'X3112'])\n",
    "ax.set_label('Traits')\n",
    "ax.set_ylabel('Standardized Value')\n",
    "bp = ax.boxplot(box_data)\n",
    "\n",
    "plt.title(f\"Traits BoxPlot\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
